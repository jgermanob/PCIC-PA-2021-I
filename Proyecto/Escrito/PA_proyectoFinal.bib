@misc{Dua:2019 ,
author = "Dua, Dheeru and Graff, Casey",
year = "2017",
title = "{UCI} Machine Learning Repository",
url = "http://archive.ics.uci.edu/ml",
institution = "University of California, Irvine, School of Information and Computer Sciences" }

@inproceedings{Brown2009ComprehensiveCS,
  title={Comprehensive Chemometrics: Set: Chemical and Biochemical Data Analysis},
  author={S. Brown and R. Ferr{\'e} and B. Walczak},
  year={2009}
}

@article{pca,
title = "Principal component analysis",
journal = "Chemometrics and Intelligent Laboratory Systems",
volume = "2",
number = "1",
pages = "37 - 52",
year = "1987",
note = "Proceedings of the Multivariate Statistical Workshop for Geologists and Geochemists",
issn = "0169-7439",
author = "Svante Wold and Kim Esbensen and Paul Geladi"
}

@book{handsonML,
author = {Gron, Aurlien},
title = {Hands-On Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems},
year = {2017},
isbn = {1491962291},
publisher = {O'Reilly Media, Inc.},
edition = {1st},
abstract = {Graphics in this book are printed in black and white. Through a series of recent breakthroughs, deep learning has boosted the entire field of machine learning. Now, even programmers who know close to nothing about this technology can use simple, efficient tools to implement programs capable of learning from data. This practical book shows you how. By using concrete examples, minimal theory, and two production-ready Python frameworksscikit-learn and Tensor Flowauthor Aurlien Gron helps you gain an intuitive understanding of the concepts and tools for building intelligent systems. Youll learn a range of techniques, starting with simple linear regression and progressing to deep neural networks. With exercises in each chapter to help you apply what youve learned, all you need is programming experience to get started. Explore the machine learning landscape, particularly neural nets Use scikit-learn to track an example machine-learning project end-to-end Explore several training models, including support vector machines, decision trees, random forests, and ensemble methods Use the Tensor Flow library to build and train neural nets Dive into neural net architectures, including convolutional nets, recurrent nets, and deep reinforcement learning Learn techniques for training and scaling deep neural nets Apply practical code examples without acquiring excessive machine learning theory or algorithm details}
}



@Manual{dask,
  title = {Dask: Library for dynamic task scheduling},
  author = {{Dask Development Team}},
  year = {2016},
  url = {https://dask.org},
}

@Article{         harris2020array,
 title         = {Array programming with {NumPy}},
 author        = {Charles R. Harris and K. Jarrod Millman and St{'{e}}fan J.
                 van der Walt and Ralf Gommers and Pauli Virtanen and David
                 Cournapeau and Eric Wieser and Julian Taylor and Sebastian
                 Berg and Nathaniel J. Smith and Robert Kern and Matti Picus
                 and Stephan Hoyer and Marten H. van Kerkwijk and Matthew
                 Brett and Allan Haldane and Jaime Fern{'{a}}ndez del
                 R{'{\i}}o and Mark Wiebe and Pearu Peterson and Pierre
                 G{'{e}}rard-Marchant and Kevin Sheppard and Tyler Reddy and
                 Warren Weckesser and Hameer Abbasi and Christoph Gohlke and
                 Travis E. Oliphant},
 year          = {2020},
 month         = sep,
 journal       = {Nature},
 volume        = {585},
 number        = {7825},
 pages         = {357--362},
 doi           = {10.1038/s41586-020-2649-2},
 publisher     = {Springer Science and Business Media {LLC}},
 url           = {https://doi.org/10.1038/s41586-020-2649-2}
}

@inproceedings{10.1145/2833157.2833162,
author = {Lam, Siu Kwan and Pitrou, Antoine and Seibert, Stanley},
title = {Numba: A LLVM-Based Python JIT Compiler},
year = {2015},
isbn = {9781450340052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2833157.2833162},
doi = {10.1145/2833157.2833162},
abstract = {Dynamic, interpreted languages, like Python, are attractive for domain-experts and scientists experimenting with new ideas. However, the performance of the interpreter is often a barrier when scaling to larger data sets. This paper presents a just-in-time compiler for Python that focuses in scientific and array-oriented computing. Starting with the simple syntax of Python, Numba compiles a subset of the language into efficient machine code that is comparable in performance to a traditional compiled language. In addition, we share our experience in building a JIT compiler using LLVM[1].},
booktitle = {Proceedings of the Second Workshop on the LLVM Compiler Infrastructure in HPC},
articleno = {7},
numpages = {6},
keywords = {LLVM, Python, compiler},
location = {Austin, Texas},
series = {LLVM '15}
}

@Book{NoceWrig06,
  Title                    = {Numerical Optimization},
  Author                   = {Jorge Nocedal and Stephen J. Wright},
  Publisher                = {Springer},
  Year                     = {2006},

  Address                  = {New York, NY, USA},
  Edition                  = {second}
}


@misc{MLCoursera, 
author = {Ng, Andrew},
title = {Machine Learning},
howpublished = "\url{https://www.coursera.org/learn/machine-learning}",
year = {2011}, 
note = "Accessed 08/02/21",
}